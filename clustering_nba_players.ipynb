{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook clustering_nba_players.ipynb to html\n",
      "[NbConvertApp] Writing 419110 bytes to clustering_nba_players.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert  clustering_nba_players.ipynb --to html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used was the classification model generated in my supervised learning project, \"Predicting NBA All Stars\" ([Blog](https://medium.com/madison-john/hey-now-youre-an-all-star-e3194b6fc44c?source=collection_home---2------0-----------------------)) ([Source](https://github.com/madxdimac/predicting_nba_all_stars)).\n",
    "\n",
    "<br></br>\n",
    "The dataset contains 11 continuous variables that measures player performance via statistical information. For details, please review the Medium blog and/or GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Apply dimensionality reduction techniques to visualize the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimensionality was reduced for visualization purposes using three approaches:\n",
    "1. Principal Components Analysis (PCA)\n",
    "2. t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "3. Uniform Manifold Approximation and Projection (UMAP)\n",
    "\n",
    "<br></br>\n",
    "![reducing dimensionality](pca_vs_tsne_vs_umap.png)\n",
    "- PCA provided the least insight and changed little with feature engineering (including/excluding variables, adding interaction variables, etc.)\n",
    "- The datapoints in the tSNE visualization, appear evenly distributed throughout the amorphous blob that was generated.\n",
    "- The UMAPS \"whale\" or \"spaceship\" shape shows areas of greater density and protrusions, indicating potential differences in those areas.\n",
    "\n",
    "<br></br>\n",
    "##### UMAPS appears to be the most useful and will be used moving forward when visualizating with clusters generated by the various clustering algorithms.\n",
    "- Specifically then different densities in the plot and the \"tail\" section is what makes this visualization the most interesting.\n",
    "- These may indicate boundaries between clusters, though admittedly, there is no strong separation in any of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Apply clustering techniques to group together similar observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The clustering algorithms used for this exercise are:\n",
    "1. K-Means Clustering\n",
    "2. Agglomerative / Hierarchiccal clustering\n",
    "3. DBSCAN\n",
    "4. GMM\n",
    "\n",
    "![clustering algorithms](cluster_algorithms_visualization_umaps_reduction.png)\n",
    "- DBSCAN\n",
    " - Difficult to find epsilon and min_samples combinations that produced 4 clusters.\n",
    " - Even so, resulting visualization indicates one cluster contains almost all of the observations.\n",
    " - DBSCAN is not useful for this dataset.\n",
    "- Agglomerative\n",
    " - Average linkage method + cosine similarity metric produced 2 large clusters and 2 much smaller clusters.\n",
    " - Complete linkage method + cosine similarity metric still produces 2 large and 2 small clusters\n",
    "     - small clusters do not appear to be as small as the ones from the previous method\n",
    " - Ward linkage method + euclidean similarity metric isolates the \"tail\" of the \"whale\" as its own cluster.\n",
    "     - This agrees with the kmeans and gmm result.\n",
    "- kmeans and gmm clusters\n",
    " - Appear similar to one another with some differences\n",
    "     - the splitting of the \"head\" of the \"whale\" for kmeans and not splitting for gmm\n",
    " - It's worth comparing these two as an exercise.\n",
    "- kmeans most resembles the agglomerative solution using ward linkage and euclidean affinity.\n",
    " - Any insights we glean from the kmeans analysis may carry over to this algorithm as well.\n",
    "\n",
    "<br></br>\n",
    "##### The kmeans, gmm, and agglomerative ward/euclidean algorithms appear better than the other three.\n",
    " - The \"tail\" section is isolated as its own cluster for all 3.\n",
    " - These appear to have the most equallly-sized clusters.\n",
    " - The clusters on either end do not overlap into each other in the middle.\n",
    " - Only clusters adjacent to each other have overlapping datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing $k$-means and GMM results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Distribution\n",
    "- For both clustering algorithms, using UMAPS dimensionality reduction to visualize, the best and worst performers are located on opposite sides of the plot.\n",
    "- The distribution of observations are different between the two algorithms.\n",
    " - Kmeans results in the less evenly distributed clustering. The smallest clusters, those containing the top and worst performers respectively, contain less than 20% of the total data between them.\n",
    " - GMM clusters are more evenly distributed, grouping more observations into the top and low end of performers.\n",
    "\n",
    "##### $k$-means\n",
    "![kmeans_labeled](kmeans_4_clusters_labeled.png)\n",
    "- Cluster 0: ~29.7% (average to above-average performers)\n",
    "- Cluster 1: ~8.7% (top performers)\n",
    "- Cluster 2: ~9.7% (poorest performers)\n",
    "- Cluster 3: ~51.9% (average to below-average performers\n",
    "\n",
    "<br></br>\n",
    "##### gmm\n",
    "![gmm_labeled](gmm_4_clusters_labeled.png)\n",
    "- Cluster 0: ~24.1% (top performers)\n",
    "- Cluster 1: ~14% (poorest performers)\n",
    "- Cluster 2: ~30.0% (average to above-average performers)\n",
    "- Cluster 3: ~31.7% (average to below-average performers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set plot style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# currently installed theme will be used to set plot style if no arguments provided\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba_stats.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SsnScr_norm_x_PER'] = df.SsnScr_norm * df.PER\n",
    "df['SsnScr_norm_x_WS'] = df.SsnScr_norm * df.WS\n",
    "df['SsnScr_norm_x_BPM'] = df.SsnScr_norm * df.BPM\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[:, 'PER':'SsnScr_norm'].dropna(axis=0).shape\n",
    "df.drop(['AllStar','Year','Player','PosGrp'], axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['AllStar','Year','Player','PosGrp'], axis=1).dropna(axis=0)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENSIONALITY REDUCTION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('PCA start...')\n",
    "pca = PCA(n_components=2).fit_transform(X)\n",
    "print('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tsne(X):\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(X)\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    return tsne_results\n",
    "\n",
    "tsne_results = run_tsne(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_umap(X):\n",
    "    time_start = time.time()\n",
    "    print('UMAP start...')\n",
    "    umap_results = umap.UMAP(n_neighbors=50, min_dist=0.1, metric='correlation').fit_transform(X)\n",
    "    print('UMAP done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    return umap_results\n",
    "    \n",
    "umap_results = run_umap(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2D plot without colors/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_repr(reduced_results):\n",
    "    time_start = time.time()\n",
    "    print('Plotting start...')\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.scatter(reduced_results[:, 0], reduced_results[:, 1], marker='.',s=3.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    print('Plotting done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2D plot with colors/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_repr_colored(reduced_results, y):\n",
    "    time_start = time.time()\n",
    "    print('Plotting start...')\n",
    "    plt.figure(figsize=(12,4))\n",
    "    colours = [\"r\",\"g\",\"y\",\"m\",\"w\",\"b\",\"c\",\"limegreen\"]\n",
    "    for i in range(reduced_results.shape[0]):\n",
    "        #print(yint(y[i]))\n",
    "        plt.text(reduced_results[i, 0], reduced_results[i, 1], str(y[i]),\n",
    "                 color=colours[int(y[i])],\n",
    "                 fontdict={'weight': 'bold', 'size': 50}\n",
    "            )\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    print('Plotting done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize reduced data w/out clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr(pca)\n",
    "plt.title('pca dimensionality reduction')\n",
    "plot_2D_repr(tsne_results)\n",
    "plt.title('tsne dimensionality reduction')\n",
    "plot_2D_repr(umap_results)\n",
    "plt.title('umap dimensionality reduction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $k$-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('k-means start...')\n",
    "kmeans_cluster = KMeans(n_clusters=4, random_state=123).fit_predict(X_std)\n",
    "print('k-means done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['KMEANS_4'] = kmeans_cluster\n",
    "y = df.KMEANS_4.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $k$-means clusters visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('k-means clustering (k=4)\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative - complete linkage, cosine affinity, 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('agglomerative start...')\n",
    "agg_cluster = AgglomerativeClustering(linkage='complete', affinity='cosine', n_clusters=4).fit_predict(X_std)\n",
    "print('agglomerative done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['AGG_4'] = agg_cluster\n",
    "y = df.AGG_4.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative clusters visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('agglomerative clustering (complete linkage, cosine affinity, 4 clusters)\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative - ward linkage, euclidean affinity, 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('agglomerative start...')\n",
    "agg_cluster = AgglomerativeClustering(linkage='ward', affinity='euclidean', n_clusters=4).fit_predict(X_std)\n",
    "print('agglomerative done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['AGG_4'] = agg_cluster\n",
    "y = df.AGG_4.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative clusters visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('agglomerative clustering (ward linkage, euclidean affinity, 4 clusters)\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative - average linkage, cosine affinity, 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('agglomerative start...')\n",
    "agg_cluster = AgglomerativeClustering(linkage='average', affinity='cosine', n_clusters=4).fit_predict(X_std)\n",
    "print('agglomerative done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['AGG_4'] = agg_cluster\n",
    "y = df.AGG_4.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### agglomerative clusters visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('agglomerative clustering (average linkage, cosine affinity, 4 clusters)\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### search epsilon"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for eps in np.arange(0.1,2.1,0.1):\n",
    "    dbscan_cluster = DBSCAN(eps=eps, min_samples=10).fit_predict(X_std)\n",
    "    print('epsilon=',eps,'num_clusters=',len(np.unique(dbscan_cluster)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### search min_samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for minPts in np.arange(1,21,1):\n",
    "    dbscan_cluster = DBSCAN(eps=1.2, min_samples=minPts).fit_predict(X_std)\n",
    "    print('minPts=',minPts,'num_clusters=',len(np.unique(dbscan_cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('dbscan start...')\n",
    "# dbscan_cluster = DBSCAN(eps=0.7, min_samples=11).fit_predict(X_std) # one big cluster in middle, other 3 on edges\n",
    "# dbscan_cluster = DBSCAN(eps=0.7, min_samples=16).fit_predict(X_std) # one big cluster in middle, other 3 on edges, slightly better than above\n",
    "dbscan_cluster = DBSCAN(eps=1.2, min_samples=6).fit_predict(X_std)\n",
    "print('dbscan done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['DBSCAN'] = dbscan_cluster\n",
    "y = df.DBSCAN.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('dbscan clustering\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print('gmm start...')\n",
    "gmm_cluster = GaussianMixture(n_components=4, random_state=123).fit_predict(X_std)\n",
    "print('gmm done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "# add to dataframe\n",
    "df = df.dropna(axis=0)\n",
    "df['GMM_4'] = gmm_cluster\n",
    "y = df.GMM_4.values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GMM clusters visualized"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_2D_repr_colored(pca, y)\n",
    "plt.title('pca dimensionality reduction')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_2D_repr_colored(tsne_results, y)\n",
    "plt.title('gmm clustering (n_components=4)\\ntsne-reduced', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_repr_colored(umap_results, y)\n",
    "plt.title('gmm clustering (n_components=4)\\numap-reduced', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTER ANALYSIS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "i = 1\n",
    "for cluster in np.unique(df.KMEANS_4):\n",
    "    plt.subplot(2,2,i)\n",
    "    i += 1\n",
    "    sns.distplot(df[df.KMEANS_4==cluster].SsnScr_norm_x_PER)\n",
    "    plt.title(f'Cluster {cluster}')\n",
    "    plt.xticks(np.arange(-10,50,5))\n",
    "\n",
    "plt.suptitle('KMEANS: SsnScr_norm_x_PER by Cluster', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "i = 1\n",
    "for cluster in np.unique(df.GMM_4):\n",
    "    plt.subplot(2,2,i)\n",
    "    i += 1\n",
    "    sns.distplot(df[df.GMM_4==cluster].SsnScr_norm_x_PER)\n",
    "    plt.title(f'Cluster {cluster}')\n",
    "    plt.xticks(np.arange(-10,50,5))\n",
    "\n",
    "plt.suptitle('GMM: SsnScr_norm_x_PER by Cluster', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "i = 1\n",
    "for cluster in np.unique(df.KMEANS_4):\n",
    "    plt.subplot(2,2,i)\n",
    "    i += 1\n",
    "    sns.distplot(df[df.KMEANS_4==cluster].SsnScr_norm_x_WS)\n",
    "    plt.title(f'Cluster {cluster}')\n",
    "    plt.xticks(np.arange(-1,20,2))\n",
    "\n",
    "plt.suptitle('KMEANS: SsnScr_norm_x_WS by Cluster', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "i = 1\n",
    "for cluster in np.unique(df.GMM_4):\n",
    "    plt.subplot(2,2,i)\n",
    "    i += 1\n",
    "    sns.distplot(df[df.GMM_4==cluster].SsnScr_norm_x_WS)\n",
    "    plt.title(f'Cluster {cluster}')\n",
    "    plt.xticks(np.arange(-1,20,2))\n",
    "\n",
    "plt.suptitle('KMEANS: SsnScr_norm_x_WS by Cluster', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
